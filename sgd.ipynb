{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация метода линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования:\n",
    "\n",
    "* l1-регуляризация\n",
    "* l2-регуляризация\n",
    "* При обучении данные подаются в SGD с помощью итератора\n",
    "* Для нахождения весов используется стохастический градиентный спуск\n",
    "* Каждый шаг градиентного спуска использует ровно один обучающий пример\n",
    "* Стохастический градиентный спуск использует приближенно вычисленный градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимо реализовать следующие (-ие) класс (-ы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    '''Класс для предсказания действительно-значного выхода по входу - вектору из R^n. \n",
    "    Используется линейная регрессия, то есть если вход X \\in R^n, вектор весов W \\in R^{n+1},\n",
    "    то значение регрессии - это [X' 1] * W, то есть y = x1*w1 + x2*w2 + xn*wn + wn+1.\n",
    "    Обучение - подгонка весов W - будет вестись на парах (x, y).\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    sgd : объект класса SGD\n",
    "    trainiterator: объект класса TrainIterator\n",
    "    n_epoch : количество эпох обучения (default = 1)\n",
    "    '''\n",
    "    def __init__(self, sgd, trainiterator, n_epoch=1):\n",
    "        pass\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        '''Обучение модели.\n",
    "        \n",
    "        Парметры\n",
    "        ----------\n",
    "        X : двумерный массив признаков размера n_samples x n_features\n",
    "        y : массив/список правильных значений размера n_samples\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        Метод обучает веса W\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\" Предсказание выходного значения для входных векторов\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : двумерный массив признаков размера n_samples x n_features\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        y : Массив размера n_samples\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def score(self, y_gt, y_pred):\n",
    "        \"\"\"Возвращает точность регрессии в виде (1 - u/v), \n",
    "        где u - суммарный квадрат расхождения y_gt с y_pred,\n",
    "        v - суммарный квадрат расхождения y_gt с матожиданием y_gt\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        y_gt : массив/список правильных значений размера n_samples\n",
    "        y_pred : массив/список предсказанных значений размера n_samples\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        accuracy - точность регрессии\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "    '''Класс для реализации метода стохастического градиентного спуска. \n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    grad : функция вычисления градиента\n",
    "    alpha : градиентный шаг (default = 1.)\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, grad, alpha=1.):\n",
    "        self.grad = grad\n",
    "        self.alpha = alpha\n",
    "     \n",
    "    def step(self, X, y, W):\n",
    "        '''Один шаг градиентного спуска.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : двумерный массив признаков размера n_samples x n_features\n",
    "        y : массив/список правильных значений размера n_samples\n",
    "        W : массив весов размера n_weights\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        Метод возвращает обновленные веса\n",
    "        '''\n",
    "        return W - self.alpha * self.grad.grad(X, y, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grad(object):\n",
    "    '''Класс для вычисления градиента по весам от функции потерь. \n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    loss : функция потерь\n",
    "    delta : параметр численного дифференцирования (default = 0.000001)    \n",
    "    '''\n",
    "    def __init__(self, loss, delta=0.000001):\n",
    "        self.loss = loss\n",
    "        self.delta = delta\n",
    "     \n",
    "    def grad(self, X, y, W):\n",
    "        '''Вычисление градиента.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : двумерный массив признаков размера n_samples x n_features\n",
    "        y : массив/список правильных значений размера n_samples\n",
    "        W : массив весов размера n_weights\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        Метод возвращает градиент по весам W в точках X от функции потерь\n",
    "        '''\n",
    "        loss = self.loss.val(X, y, W)\n",
    "        gradient = list()\n",
    "        for d in np.eye(len(X)) * self.delta:\n",
    "            gradient[i] = (self.loss.val(X, y, W + d) - loss) / self.delta\n",
    "        return np.array(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "    '''Класс для вычисления функции потерь. \n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    l1_coef : коэффициент l1 регуляризации (default = 0)\n",
    "    l2_coef : коэффициент l2 регуляризации (default = 0)\n",
    "    '''\n",
    "    def __init__(self, l1_coef=0, l2_coef=0):\n",
    "        self.l1 = l1_coef\n",
    "        self.l2 = l2_coef\n",
    "     \n",
    "    def val(self, X, y, W):\n",
    "        '''Вычисление функции потерь.\n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        X : двумерный массив признаков размера n_samples x n_features\n",
    "        y : массив/список правильных значений размера n_samples\n",
    "        W : массив весов размера n_weights\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        Метод возвращает значение функции потерь в точках X\n",
    "        '''\n",
    "        return (W @ X - y) ** 2 + self.l1 * sum(abs(W)) + self.l2 * sum(W ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainIterator(object):\n",
    "    '''Класс итератора для работы с обучающими данными. \n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    X : двумерный массив признаков размера n_samples x n_features\n",
    "    y : массив/список правильных значений размера n_samples\n",
    "    n_epoch : количество эпох обучения (default = 1)\n",
    "    '''    \n",
    "    def __init__(self, X, y, n_epoch=1):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_epoch = n_epoch\n",
    "        self.i = -1\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        '''Нужно для использования итератора в цикле for\n",
    "        Здесь ничего менять не надо\n",
    "        '''\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        '''Выдача следующего примера.\n",
    "        \n",
    "        Выход\n",
    "        -------\n",
    "        Метод возвращает очередной пример как из X, так и из y\n",
    "        '''\n",
    "        self.i += 1\n",
    "        if self.i >= self.X.shape[0]:\n",
    "            self.i = 0\n",
    "            self.epoch += 1\n",
    "        if self.epoch >= self.n_epoch:\n",
    "            raise StopIteration\n",
    "        return self.X[self.i], self.y[self.i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO подгружаем данные в trainX, trainY, testX, testY\n",
    "#TODO задаем alpha, delta, l1_coef, l2_coef, n_epoch\n",
    "\n",
    "trainiterator = TrainIterator(trainX, trainY, n_epoch)\n",
    "loss = Loss(l1_coef, l2_coef)\n",
    "grad = Grad(loss, delta)\n",
    "sgd = SGD(grad, alpha)\n",
    "reg = Regression(sgd, trainiterator, n_epoch)\n",
    "reg.fit(trainX, trainY)\n",
    "y_pred = reg.predict(testX)\n",
    "acc = reg.score(testY, y_pred)\n",
    "print('Your accuracy is %s' % str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Покройте ваш класс тестами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подберите оптимальные параметры для вашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужно подобрать alpha, delta, l1_coef, l2_coef, n_epoch для максимизации score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}