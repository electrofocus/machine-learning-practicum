{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('venv')",
   "display_name": "Python 3.8.2 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "10b4a0ed2be80746f49ec87768e33da4ad1b65ae86b1210b2ddb2c379d80788b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      index  Category  Rating       Reviews      Size      Installs  Type  \\\n",
       "0         0     0.001   0.041  1.590000e-07  0.001946  1.000000e-07  0.01   \n",
       "1         1     0.001   0.039  9.670000e-07  0.001434  5.000000e-06  0.01   \n",
       "2         2     0.001   0.047  8.751000e-05  0.000891  5.000000e-05  0.01   \n",
       "3         3     0.001   0.045  2.156440e-04  0.002560  5.000000e-04  0.01   \n",
       "4         4     0.001   0.043  9.670000e-07  0.000287  1.000000e-06  0.01   \n",
       "...     ...       ...     ...           ...       ...           ...   ...   \n",
       "7715  10829     0.004   0.048  4.400000e-08  0.000062  1.000000e-08  0.01   \n",
       "7716  10830     0.020   0.040  7.000000e-09  0.000266  5.000000e-09  0.01   \n",
       "7717  10832     0.020   0.045  3.800000e-08  0.005427  5.000000e-08  0.01   \n",
       "7718  10833     0.020   0.050  4.000000e-09  0.000369  1.000000e-09  0.01   \n",
       "7719  10836     0.018   0.045  3.983070e-04  0.001946  1.000000e-04  0.01   \n",
       "\n",
       "      Price  Content Rating  Genres  Last Updated  \n",
       "0       0.0            0.01   0.001       0.00325  \n",
       "1       0.0            0.01   0.000       0.00317  \n",
       "2       0.0            0.01   0.001       0.00119  \n",
       "3       0.0            0.02   0.001       0.00173  \n",
       "4       0.0            0.01   0.000       0.00161  \n",
       "...     ...             ...     ...           ...  \n",
       "7715    0.0            0.01   0.004       0.01711  \n",
       "7716    0.0            0.01   0.009       0.00528  \n",
       "7717    0.0            0.01   0.009       0.00491  \n",
       "7718    0.0            0.01   0.009       0.00145  \n",
       "7719    0.0            0.01   0.017       0.00126  \n",
       "\n",
       "[7720 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Category</th>\n      <th>Rating</th>\n      <th>Reviews</th>\n      <th>Size</th>\n      <th>Installs</th>\n      <th>Type</th>\n      <th>Price</th>\n      <th>Content Rating</th>\n      <th>Genres</th>\n      <th>Last Updated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.001</td>\n      <td>0.041</td>\n      <td>1.590000e-07</td>\n      <td>0.001946</td>\n      <td>1.000000e-07</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.001</td>\n      <td>0.00325</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.001</td>\n      <td>0.039</td>\n      <td>9.670000e-07</td>\n      <td>0.001434</td>\n      <td>5.000000e-06</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.000</td>\n      <td>0.00317</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.001</td>\n      <td>0.047</td>\n      <td>8.751000e-05</td>\n      <td>0.000891</td>\n      <td>5.000000e-05</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.001</td>\n      <td>0.00119</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.001</td>\n      <td>0.045</td>\n      <td>2.156440e-04</td>\n      <td>0.002560</td>\n      <td>5.000000e-04</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.001</td>\n      <td>0.00173</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.001</td>\n      <td>0.043</td>\n      <td>9.670000e-07</td>\n      <td>0.000287</td>\n      <td>1.000000e-06</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.000</td>\n      <td>0.00161</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7715</th>\n      <td>10829</td>\n      <td>0.004</td>\n      <td>0.048</td>\n      <td>4.400000e-08</td>\n      <td>0.000062</td>\n      <td>1.000000e-08</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.004</td>\n      <td>0.01711</td>\n    </tr>\n    <tr>\n      <th>7716</th>\n      <td>10830</td>\n      <td>0.020</td>\n      <td>0.040</td>\n      <td>7.000000e-09</td>\n      <td>0.000266</td>\n      <td>5.000000e-09</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.009</td>\n      <td>0.00528</td>\n    </tr>\n    <tr>\n      <th>7717</th>\n      <td>10832</td>\n      <td>0.020</td>\n      <td>0.045</td>\n      <td>3.800000e-08</td>\n      <td>0.005427</td>\n      <td>5.000000e-08</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.009</td>\n      <td>0.00491</td>\n    </tr>\n    <tr>\n      <th>7718</th>\n      <td>10833</td>\n      <td>0.020</td>\n      <td>0.050</td>\n      <td>4.000000e-09</td>\n      <td>0.000369</td>\n      <td>1.000000e-09</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.009</td>\n      <td>0.00145</td>\n    </tr>\n    <tr>\n      <th>7719</th>\n      <td>10836</td>\n      <td>0.018</td>\n      <td>0.045</td>\n      <td>3.983070e-04</td>\n      <td>0.001946</td>\n      <td>1.000000e-04</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.017</td>\n      <td>0.00126</td>\n    </tr>\n  </tbody>\n</table>\n<p>7720 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv('../data/input/googleplaystore_norm.csv', delimiter='\\t')\n",
    "data"
   ]
  },
  {
   "source": [
    "### Подготовка данных"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Category  Rating       Reviews  ...  Content Rating  Genres  Last Updated\n",
       "0        0.001   0.041  1.590000e-07  ...            0.01   0.001       0.00325\n",
       "1        0.001   0.039  9.670000e-07  ...            0.01   0.000       0.00317\n",
       "2        0.001   0.047  8.751000e-05  ...            0.01   0.001       0.00119\n",
       "3        0.001   0.045  2.156440e-04  ...            0.02   0.001       0.00173\n",
       "4        0.001   0.043  9.670000e-07  ...            0.01   0.000       0.00161\n",
       "...        ...     ...           ...  ...             ...     ...           ...\n",
       "7715     0.004   0.048  4.400000e-08  ...            0.01   0.004       0.01711\n",
       "7716     0.020   0.040  7.000000e-09  ...            0.01   0.009       0.00528\n",
       "7717     0.020   0.045  3.800000e-08  ...            0.01   0.009       0.00491\n",
       "7718     0.020   0.050  4.000000e-09  ...            0.01   0.009       0.00145\n",
       "7719     0.018   0.045  3.983070e-04  ...            0.01   0.017       0.00126\n",
       "\n",
       "[7720 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Rating</th>\n      <th>Reviews</th>\n      <th>Size</th>\n      <th>Installs</th>\n      <th>Type</th>\n      <th>Price</th>\n      <th>Content Rating</th>\n      <th>Genres</th>\n      <th>Last Updated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001</td>\n      <td>0.041</td>\n      <td>1.590000e-07</td>\n      <td>0.001946</td>\n      <td>1.000000e-07</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.001</td>\n      <td>0.00325</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001</td>\n      <td>0.039</td>\n      <td>9.670000e-07</td>\n      <td>0.001434</td>\n      <td>5.000000e-06</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.000</td>\n      <td>0.00317</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.001</td>\n      <td>0.047</td>\n      <td>8.751000e-05</td>\n      <td>0.000891</td>\n      <td>5.000000e-05</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.001</td>\n      <td>0.00119</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001</td>\n      <td>0.045</td>\n      <td>2.156440e-04</td>\n      <td>0.002560</td>\n      <td>5.000000e-04</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.02</td>\n      <td>0.001</td>\n      <td>0.00173</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001</td>\n      <td>0.043</td>\n      <td>9.670000e-07</td>\n      <td>0.000287</td>\n      <td>1.000000e-06</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.000</td>\n      <td>0.00161</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7715</th>\n      <td>0.004</td>\n      <td>0.048</td>\n      <td>4.400000e-08</td>\n      <td>0.000062</td>\n      <td>1.000000e-08</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.004</td>\n      <td>0.01711</td>\n    </tr>\n    <tr>\n      <th>7716</th>\n      <td>0.020</td>\n      <td>0.040</td>\n      <td>7.000000e-09</td>\n      <td>0.000266</td>\n      <td>5.000000e-09</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.009</td>\n      <td>0.00528</td>\n    </tr>\n    <tr>\n      <th>7717</th>\n      <td>0.020</td>\n      <td>0.045</td>\n      <td>3.800000e-08</td>\n      <td>0.005427</td>\n      <td>5.000000e-08</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.009</td>\n      <td>0.00491</td>\n    </tr>\n    <tr>\n      <th>7718</th>\n      <td>0.020</td>\n      <td>0.050</td>\n      <td>4.000000e-09</td>\n      <td>0.000369</td>\n      <td>1.000000e-09</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.009</td>\n      <td>0.00145</td>\n    </tr>\n    <tr>\n      <th>7719</th>\n      <td>0.018</td>\n      <td>0.045</td>\n      <td>3.983070e-04</td>\n      <td>0.001946</td>\n      <td>1.000000e-04</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.017</td>\n      <td>0.00126</td>\n    </tr>\n  </tbody>\n</table>\n<p>7720 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data = data.drop(columns='index')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((6000, 10), (1720, 10))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "x_train = data[:6000].values\n",
    "x_test = data[6000:].values\n",
    "\n",
    "y_train = x_train\n",
    "y_test = x_test\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "source": [
    "### Модель"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"AE\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlayer1 (Dense)               (None, 5)                 55        \n_________________________________________________________________\nlayer2 (Dense)               (None, 10)                60        \n=================================================================\nTotal params: 115\nTrainable params: 115\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(10,)),\n",
    "        layers.Dense(5, activation='sigmoid', name='layer1'),\n",
    "        layers.Dense(10, activation='sigmoid', name='layer2'),\n",
    "    ],\n",
    "    name='AE'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "### Гиперпараметры"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=1)\n",
    "f_loss = keras.losses.MeanSquaredError()\n",
    "met = ['accuracy']\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=f_loss,\n",
    "    metrics=met\n",
    ")"
   ]
  },
  {
   "source": [
    "### Обучение"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.6691e-05 - accuracy: 0.8685 - val_loss: 4.2831e-05 - val_accuracy: 0.8384\n",
      "Epoch 2/300\n",
      "100/100 [==============================] - 0s 957us/step - loss: 4.6638e-05 - accuracy: 0.8685 - val_loss: 4.2781e-05 - val_accuracy: 0.8384\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6587e-05 - accuracy: 0.8685 - val_loss: 4.2732e-05 - val_accuracy: 0.8384\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6536e-05 - accuracy: 0.8685 - val_loss: 4.2684e-05 - val_accuracy: 0.8384\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6486e-05 - accuracy: 0.8685 - val_loss: 4.2636e-05 - val_accuracy: 0.8384\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6437e-05 - accuracy: 0.8685 - val_loss: 4.2589e-05 - val_accuracy: 0.8384\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6388e-05 - accuracy: 0.8685 - val_loss: 4.2543e-05 - val_accuracy: 0.8384\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6340e-05 - accuracy: 0.8685 - val_loss: 4.2497e-05 - val_accuracy: 0.8384\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6294e-05 - accuracy: 0.8685 - val_loss: 4.2452e-05 - val_accuracy: 0.8384\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6247e-05 - accuracy: 0.8685 - val_loss: 4.2408e-05 - val_accuracy: 0.8384\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - 0s 940us/step - loss: 4.6202e-05 - accuracy: 0.8685 - val_loss: 4.2365e-05 - val_accuracy: 0.8384\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - 0s 994us/step - loss: 4.6157e-05 - accuracy: 0.8685 - val_loss: 4.2322e-05 - val_accuracy: 0.8384\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - 0s 944us/step - loss: 4.6113e-05 - accuracy: 0.8685 - val_loss: 4.2280e-05 - val_accuracy: 0.8384\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6069e-05 - accuracy: 0.8685 - val_loss: 4.2238e-05 - val_accuracy: 0.8384\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6026e-05 - accuracy: 0.8685 - val_loss: 4.2197e-05 - val_accuracy: 0.8384\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5984e-05 - accuracy: 0.8685 - val_loss: 4.2157e-05 - val_accuracy: 0.8384\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5942e-05 - accuracy: 0.8685 - val_loss: 4.2117e-05 - val_accuracy: 0.8384\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5901e-05 - accuracy: 0.8685 - val_loss: 4.2078e-05 - val_accuracy: 0.8384\n",
      "Epoch 19/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5861e-05 - accuracy: 0.8685 - val_loss: 4.2040e-05 - val_accuracy: 0.8384\n",
      "Epoch 20/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5821e-05 - accuracy: 0.8685 - val_loss: 4.2002e-05 - val_accuracy: 0.8384\n",
      "Epoch 21/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5782e-05 - accuracy: 0.8685 - val_loss: 4.1964e-05 - val_accuracy: 0.8384\n",
      "Epoch 22/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5743e-05 - accuracy: 0.8685 - val_loss: 4.1927e-05 - val_accuracy: 0.8384\n",
      "Epoch 23/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5705e-05 - accuracy: 0.8685 - val_loss: 4.1890e-05 - val_accuracy: 0.8384\n",
      "Epoch 24/300\n",
      "100/100 [==============================] - 0s 883us/step - loss: 4.5667e-05 - accuracy: 0.8685 - val_loss: 4.1854e-05 - val_accuracy: 0.8384\n",
      "Epoch 25/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5630e-05 - accuracy: 0.8685 - val_loss: 4.1819e-05 - val_accuracy: 0.8384\n",
      "Epoch 26/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5593e-05 - accuracy: 0.8685 - val_loss: 4.1784e-05 - val_accuracy: 0.8384\n",
      "Epoch 27/300\n",
      "100/100 [==============================] - 0s 987us/step - loss: 4.5557e-05 - accuracy: 0.8685 - val_loss: 4.1749e-05 - val_accuracy: 0.8384\n",
      "Epoch 28/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5521e-05 - accuracy: 0.8685 - val_loss: 4.1715e-05 - val_accuracy: 0.8384\n",
      "Epoch 29/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5486e-05 - accuracy: 0.8685 - val_loss: 4.1681e-05 - val_accuracy: 0.8384\n",
      "Epoch 30/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5451e-05 - accuracy: 0.8685 - val_loss: 4.1648e-05 - val_accuracy: 0.8384\n",
      "Epoch 31/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5417e-05 - accuracy: 0.8685 - val_loss: 4.1615e-05 - val_accuracy: 0.8384\n",
      "Epoch 32/300\n",
      "100/100 [==============================] - 0s 977us/step - loss: 4.5383e-05 - accuracy: 0.8685 - val_loss: 4.1583e-05 - val_accuracy: 0.8384\n",
      "Epoch 33/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5349e-05 - accuracy: 0.8685 - val_loss: 4.1551e-05 - val_accuracy: 0.8384\n",
      "Epoch 34/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5317e-05 - accuracy: 0.8685 - val_loss: 4.1519e-05 - val_accuracy: 0.8384\n",
      "Epoch 35/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5284e-05 - accuracy: 0.8685 - val_loss: 4.1488e-05 - val_accuracy: 0.8384\n",
      "Epoch 36/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5252e-05 - accuracy: 0.8685 - val_loss: 4.1458e-05 - val_accuracy: 0.8384\n",
      "Epoch 37/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5220e-05 - accuracy: 0.8685 - val_loss: 4.1427e-05 - val_accuracy: 0.8384\n",
      "Epoch 38/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5189e-05 - accuracy: 0.8685 - val_loss: 4.1397e-05 - val_accuracy: 0.8384\n",
      "Epoch 39/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5158e-05 - accuracy: 0.8685 - val_loss: 4.1368e-05 - val_accuracy: 0.8384\n",
      "Epoch 40/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5127e-05 - accuracy: 0.8685 - val_loss: 4.1338e-05 - val_accuracy: 0.8384\n",
      "Epoch 41/300\n",
      "100/100 [==============================] - 0s 947us/step - loss: 4.5097e-05 - accuracy: 0.8685 - val_loss: 4.1310e-05 - val_accuracy: 0.8384\n",
      "Epoch 42/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5067e-05 - accuracy: 0.8685 - val_loss: 4.1281e-05 - val_accuracy: 0.8384\n",
      "Epoch 43/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5038e-05 - accuracy: 0.8685 - val_loss: 4.1253e-05 - val_accuracy: 0.8384\n",
      "Epoch 44/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5009e-05 - accuracy: 0.8685 - val_loss: 4.1225e-05 - val_accuracy: 0.8384\n",
      "Epoch 45/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4980e-05 - accuracy: 0.8685 - val_loss: 4.1198e-05 - val_accuracy: 0.8384\n",
      "Epoch 46/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4952e-05 - accuracy: 0.8685 - val_loss: 4.1171e-05 - val_accuracy: 0.8384\n",
      "Epoch 47/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4924e-05 - accuracy: 0.8685 - val_loss: 4.1144e-05 - val_accuracy: 0.8384\n",
      "Epoch 48/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4896e-05 - accuracy: 0.8685 - val_loss: 4.1118e-05 - val_accuracy: 0.8384\n",
      "Epoch 49/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4869e-05 - accuracy: 0.8685 - val_loss: 4.1092e-05 - val_accuracy: 0.8384\n",
      "Epoch 50/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4842e-05 - accuracy: 0.8685 - val_loss: 4.1066e-05 - val_accuracy: 0.8384\n",
      "Epoch 51/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4815e-05 - accuracy: 0.8685 - val_loss: 4.1041e-05 - val_accuracy: 0.8384\n",
      "Epoch 52/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4788e-05 - accuracy: 0.8685 - val_loss: 4.1016e-05 - val_accuracy: 0.8384\n",
      "Epoch 53/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4762e-05 - accuracy: 0.8685 - val_loss: 4.0991e-05 - val_accuracy: 0.8384\n",
      "Epoch 54/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4737e-05 - accuracy: 0.8685 - val_loss: 4.0966e-05 - val_accuracy: 0.8384\n",
      "Epoch 55/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4711e-05 - accuracy: 0.8685 - val_loss: 4.0942e-05 - val_accuracy: 0.8384\n",
      "Epoch 56/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4686e-05 - accuracy: 0.8685 - val_loss: 4.0918e-05 - val_accuracy: 0.8384\n",
      "Epoch 57/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4661e-05 - accuracy: 0.8685 - val_loss: 4.0894e-05 - val_accuracy: 0.8384\n",
      "Epoch 58/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4636e-05 - accuracy: 0.8685 - val_loss: 4.0871e-05 - val_accuracy: 0.8384\n",
      "Epoch 59/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4612e-05 - accuracy: 0.8685 - val_loss: 4.0847e-05 - val_accuracy: 0.8384\n",
      "Epoch 60/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4588e-05 - accuracy: 0.8685 - val_loss: 4.0824e-05 - val_accuracy: 0.8384\n",
      "Epoch 61/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4564e-05 - accuracy: 0.8685 - val_loss: 4.0802e-05 - val_accuracy: 0.8384\n",
      "Epoch 62/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4540e-05 - accuracy: 0.8685 - val_loss: 4.0779e-05 - val_accuracy: 0.8384\n",
      "Epoch 63/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4517e-05 - accuracy: 0.8685 - val_loss: 4.0757e-05 - val_accuracy: 0.8384\n",
      "Epoch 64/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4494e-05 - accuracy: 0.8685 - val_loss: 4.0735e-05 - val_accuracy: 0.8384\n",
      "Epoch 65/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4471e-05 - accuracy: 0.8685 - val_loss: 4.0714e-05 - val_accuracy: 0.8384\n",
      "Epoch 66/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4449e-05 - accuracy: 0.8685 - val_loss: 4.0692e-05 - val_accuracy: 0.8384\n",
      "Epoch 67/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4426e-05 - accuracy: 0.8685 - val_loss: 4.0671e-05 - val_accuracy: 0.8384\n",
      "Epoch 68/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4404e-05 - accuracy: 0.8685 - val_loss: 4.0650e-05 - val_accuracy: 0.8384\n",
      "Epoch 69/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4382e-05 - accuracy: 0.8685 - val_loss: 4.0630e-05 - val_accuracy: 0.8384\n",
      "Epoch 70/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4361e-05 - accuracy: 0.8685 - val_loss: 4.0609e-05 - val_accuracy: 0.8384\n",
      "Epoch 71/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4339e-05 - accuracy: 0.8685 - val_loss: 4.0589e-05 - val_accuracy: 0.8384\n",
      "Epoch 72/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4318e-05 - accuracy: 0.8685 - val_loss: 4.0569e-05 - val_accuracy: 0.8384\n",
      "Epoch 73/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4297e-05 - accuracy: 0.8685 - val_loss: 4.0549e-05 - val_accuracy: 0.8384\n",
      "Epoch 74/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4276e-05 - accuracy: 0.8685 - val_loss: 4.0529e-05 - val_accuracy: 0.8384\n",
      "Epoch 75/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4256e-05 - accuracy: 0.8685 - val_loss: 4.0510e-05 - val_accuracy: 0.8384\n",
      "Epoch 76/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4236e-05 - accuracy: 0.8685 - val_loss: 4.0490e-05 - val_accuracy: 0.8384\n",
      "Epoch 77/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4216e-05 - accuracy: 0.8685 - val_loss: 4.0471e-05 - val_accuracy: 0.8384\n",
      "Epoch 78/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4196e-05 - accuracy: 0.8685 - val_loss: 4.0452e-05 - val_accuracy: 0.8384\n",
      "Epoch 79/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4176e-05 - accuracy: 0.8685 - val_loss: 4.0434e-05 - val_accuracy: 0.8384\n",
      "Epoch 80/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4157e-05 - accuracy: 0.8685 - val_loss: 4.0415e-05 - val_accuracy: 0.8384\n",
      "Epoch 81/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4137e-05 - accuracy: 0.8685 - val_loss: 4.0397e-05 - val_accuracy: 0.8384\n",
      "Epoch 82/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4118e-05 - accuracy: 0.8685 - val_loss: 4.0379e-05 - val_accuracy: 0.8384\n",
      "Epoch 83/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4099e-05 - accuracy: 0.8685 - val_loss: 4.0361e-05 - val_accuracy: 0.8384\n",
      "Epoch 84/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4081e-05 - accuracy: 0.8685 - val_loss: 4.0343e-05 - val_accuracy: 0.8384\n",
      "Epoch 85/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4062e-05 - accuracy: 0.8685 - val_loss: 4.0326e-05 - val_accuracy: 0.8384\n",
      "Epoch 86/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4044e-05 - accuracy: 0.8685 - val_loss: 4.0309e-05 - val_accuracy: 0.8384\n",
      "Epoch 87/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4025e-05 - accuracy: 0.8685 - val_loss: 4.0292e-05 - val_accuracy: 0.8384\n",
      "Epoch 88/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4007e-05 - accuracy: 0.8685 - val_loss: 4.0275e-05 - val_accuracy: 0.8384\n",
      "Epoch 89/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3990e-05 - accuracy: 0.8685 - val_loss: 4.0258e-05 - val_accuracy: 0.8384\n",
      "Epoch 90/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3972e-05 - accuracy: 0.8685 - val_loss: 4.0241e-05 - val_accuracy: 0.8384\n",
      "Epoch 91/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3954e-05 - accuracy: 0.8685 - val_loss: 4.0225e-05 - val_accuracy: 0.8384\n",
      "Epoch 92/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3937e-05 - accuracy: 0.8685 - val_loss: 4.0208e-05 - val_accuracy: 0.8384\n",
      "Epoch 93/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3920e-05 - accuracy: 0.8685 - val_loss: 4.0192e-05 - val_accuracy: 0.8384\n",
      "Epoch 94/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3903e-05 - accuracy: 0.8685 - val_loss: 4.0176e-05 - val_accuracy: 0.8384\n",
      "Epoch 95/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3886e-05 - accuracy: 0.8685 - val_loss: 4.0160e-05 - val_accuracy: 0.8384\n",
      "Epoch 96/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3869e-05 - accuracy: 0.8685 - val_loss: 4.0144e-05 - val_accuracy: 0.8384\n",
      "Epoch 97/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3853e-05 - accuracy: 0.8685 - val_loss: 4.0129e-05 - val_accuracy: 0.8384\n",
      "Epoch 98/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3836e-05 - accuracy: 0.8685 - val_loss: 4.0114e-05 - val_accuracy: 0.8384\n",
      "Epoch 99/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3820e-05 - accuracy: 0.8685 - val_loss: 4.0098e-05 - val_accuracy: 0.8384\n",
      "Epoch 100/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3804e-05 - accuracy: 0.8685 - val_loss: 4.0083e-05 - val_accuracy: 0.8384\n",
      "Epoch 101/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3788e-05 - accuracy: 0.8685 - val_loss: 4.0068e-05 - val_accuracy: 0.8384\n",
      "Epoch 102/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3772e-05 - accuracy: 0.8685 - val_loss: 4.0053e-05 - val_accuracy: 0.8384\n",
      "Epoch 103/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3757e-05 - accuracy: 0.8685 - val_loss: 4.0039e-05 - val_accuracy: 0.8384\n",
      "Epoch 104/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3741e-05 - accuracy: 0.8685 - val_loss: 4.0024e-05 - val_accuracy: 0.8384\n",
      "Epoch 105/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3726e-05 - accuracy: 0.8685 - val_loss: 4.0010e-05 - val_accuracy: 0.8384\n",
      "Epoch 106/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3711e-05 - accuracy: 0.8685 - val_loss: 3.9996e-05 - val_accuracy: 0.8384\n",
      "Epoch 107/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3696e-05 - accuracy: 0.8685 - val_loss: 3.9982e-05 - val_accuracy: 0.8384\n",
      "Epoch 108/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3681e-05 - accuracy: 0.8685 - val_loss: 3.9968e-05 - val_accuracy: 0.8384\n",
      "Epoch 109/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3666e-05 - accuracy: 0.8685 - val_loss: 3.9954e-05 - val_accuracy: 0.8384\n",
      "Epoch 110/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3651e-05 - accuracy: 0.8685 - val_loss: 3.9940e-05 - val_accuracy: 0.8384\n",
      "Epoch 111/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3637e-05 - accuracy: 0.8685 - val_loss: 3.9926e-05 - val_accuracy: 0.8384\n",
      "Epoch 112/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3622e-05 - accuracy: 0.8685 - val_loss: 3.9913e-05 - val_accuracy: 0.8384\n",
      "Epoch 113/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3608e-05 - accuracy: 0.8685 - val_loss: 3.9899e-05 - val_accuracy: 0.8384\n",
      "Epoch 114/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3594e-05 - accuracy: 0.8685 - val_loss: 3.9886e-05 - val_accuracy: 0.8384\n",
      "Epoch 115/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3580e-05 - accuracy: 0.8685 - val_loss: 3.9873e-05 - val_accuracy: 0.8384\n",
      "Epoch 116/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3566e-05 - accuracy: 0.8685 - val_loss: 3.9860e-05 - val_accuracy: 0.8384\n",
      "Epoch 117/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3552e-05 - accuracy: 0.8685 - val_loss: 3.9847e-05 - val_accuracy: 0.8384\n",
      "Epoch 118/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3538e-05 - accuracy: 0.8685 - val_loss: 3.9834e-05 - val_accuracy: 0.8384\n",
      "Epoch 119/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3525e-05 - accuracy: 0.8685 - val_loss: 3.9822e-05 - val_accuracy: 0.8384\n",
      "Epoch 120/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3511e-05 - accuracy: 0.8685 - val_loss: 3.9809e-05 - val_accuracy: 0.8384\n",
      "Epoch 121/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3498e-05 - accuracy: 0.8685 - val_loss: 3.9797e-05 - val_accuracy: 0.8384\n",
      "Epoch 122/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3484e-05 - accuracy: 0.8685 - val_loss: 3.9784e-05 - val_accuracy: 0.8384\n",
      "Epoch 123/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3471e-05 - accuracy: 0.8685 - val_loss: 3.9772e-05 - val_accuracy: 0.8384\n",
      "Epoch 124/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3458e-05 - accuracy: 0.8685 - val_loss: 3.9760e-05 - val_accuracy: 0.8384\n",
      "Epoch 125/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3445e-05 - accuracy: 0.8685 - val_loss: 3.9748e-05 - val_accuracy: 0.8384\n",
      "Epoch 126/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3433e-05 - accuracy: 0.8685 - val_loss: 3.9736e-05 - val_accuracy: 0.8384\n",
      "Epoch 127/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3420e-05 - accuracy: 0.8685 - val_loss: 3.9724e-05 - val_accuracy: 0.8384\n",
      "Epoch 128/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3407e-05 - accuracy: 0.8685 - val_loss: 3.9712e-05 - val_accuracy: 0.8384\n",
      "Epoch 129/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3395e-05 - accuracy: 0.8685 - val_loss: 3.9701e-05 - val_accuracy: 0.8384\n",
      "Epoch 130/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3382e-05 - accuracy: 0.8685 - val_loss: 3.9689e-05 - val_accuracy: 0.8384\n",
      "Epoch 131/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3370e-05 - accuracy: 0.8685 - val_loss: 3.9678e-05 - val_accuracy: 0.8384\n",
      "Epoch 132/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3358e-05 - accuracy: 0.8685 - val_loss: 3.9666e-05 - val_accuracy: 0.8384\n",
      "Epoch 133/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3346e-05 - accuracy: 0.8685 - val_loss: 3.9655e-05 - val_accuracy: 0.8384\n",
      "Epoch 134/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3333e-05 - accuracy: 0.8685 - val_loss: 3.9644e-05 - val_accuracy: 0.8384\n",
      "Epoch 135/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3322e-05 - accuracy: 0.8685 - val_loss: 3.9633e-05 - val_accuracy: 0.8384\n",
      "Epoch 136/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3310e-05 - accuracy: 0.8685 - val_loss: 3.9622e-05 - val_accuracy: 0.8384\n",
      "Epoch 137/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3298e-05 - accuracy: 0.8685 - val_loss: 3.9611e-05 - val_accuracy: 0.8384\n",
      "Epoch 138/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3286e-05 - accuracy: 0.8685 - val_loss: 3.9601e-05 - val_accuracy: 0.8384\n",
      "Epoch 139/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3275e-05 - accuracy: 0.8685 - val_loss: 3.9590e-05 - val_accuracy: 0.8384\n",
      "Epoch 140/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3263e-05 - accuracy: 0.8685 - val_loss: 3.9579e-05 - val_accuracy: 0.8384\n",
      "Epoch 141/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3252e-05 - accuracy: 0.8685 - val_loss: 3.9569e-05 - val_accuracy: 0.8384\n",
      "Epoch 142/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3241e-05 - accuracy: 0.8685 - val_loss: 3.9558e-05 - val_accuracy: 0.8384\n",
      "Epoch 143/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3229e-05 - accuracy: 0.8685 - val_loss: 3.9548e-05 - val_accuracy: 0.8384\n",
      "Epoch 144/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3218e-05 - accuracy: 0.8685 - val_loss: 3.9538e-05 - val_accuracy: 0.8384\n",
      "Epoch 145/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3207e-05 - accuracy: 0.8685 - val_loss: 3.9527e-05 - val_accuracy: 0.8384\n",
      "Epoch 146/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3196e-05 - accuracy: 0.8685 - val_loss: 3.9517e-05 - val_accuracy: 0.8384\n",
      "Epoch 147/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3186e-05 - accuracy: 0.8685 - val_loss: 3.9507e-05 - val_accuracy: 0.8384\n",
      "Epoch 148/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3175e-05 - accuracy: 0.8685 - val_loss: 3.9497e-05 - val_accuracy: 0.8384\n",
      "Epoch 149/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3164e-05 - accuracy: 0.8685 - val_loss: 3.9487e-05 - val_accuracy: 0.8384\n",
      "Epoch 150/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3153e-05 - accuracy: 0.8685 - val_loss: 3.9477e-05 - val_accuracy: 0.8384\n",
      "Epoch 151/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3143e-05 - accuracy: 0.8685 - val_loss: 3.9468e-05 - val_accuracy: 0.8384\n",
      "Epoch 152/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3132e-05 - accuracy: 0.8685 - val_loss: 3.9458e-05 - val_accuracy: 0.8384\n",
      "Epoch 153/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3122e-05 - accuracy: 0.8685 - val_loss: 3.9448e-05 - val_accuracy: 0.8384\n",
      "Epoch 154/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3112e-05 - accuracy: 0.8685 - val_loss: 3.9439e-05 - val_accuracy: 0.8384\n",
      "Epoch 155/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3101e-05 - accuracy: 0.8685 - val_loss: 3.9430e-05 - val_accuracy: 0.8384\n",
      "Epoch 156/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3091e-05 - accuracy: 0.8685 - val_loss: 3.9420e-05 - val_accuracy: 0.8384\n",
      "Epoch 157/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3081e-05 - accuracy: 0.8685 - val_loss: 3.9411e-05 - val_accuracy: 0.8384\n",
      "Epoch 158/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3071e-05 - accuracy: 0.8685 - val_loss: 3.9401e-05 - val_accuracy: 0.8384\n",
      "Epoch 159/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3061e-05 - accuracy: 0.8685 - val_loss: 3.9392e-05 - val_accuracy: 0.8384\n",
      "Epoch 160/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3051e-05 - accuracy: 0.8685 - val_loss: 3.9383e-05 - val_accuracy: 0.8384\n",
      "Epoch 161/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3042e-05 - accuracy: 0.8685 - val_loss: 3.9374e-05 - val_accuracy: 0.8384\n",
      "Epoch 162/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3032e-05 - accuracy: 0.8685 - val_loss: 3.9365e-05 - val_accuracy: 0.8384\n",
      "Epoch 163/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3022e-05 - accuracy: 0.8685 - val_loss: 3.9356e-05 - val_accuracy: 0.8384\n",
      "Epoch 164/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3013e-05 - accuracy: 0.8685 - val_loss: 3.9347e-05 - val_accuracy: 0.8384\n",
      "Epoch 165/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3003e-05 - accuracy: 0.8685 - val_loss: 3.9339e-05 - val_accuracy: 0.8384\n",
      "Epoch 166/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2994e-05 - accuracy: 0.8685 - val_loss: 3.9330e-05 - val_accuracy: 0.8384\n",
      "Epoch 167/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2984e-05 - accuracy: 0.8685 - val_loss: 3.9322e-05 - val_accuracy: 0.8384\n",
      "Epoch 168/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2975e-05 - accuracy: 0.8685 - val_loss: 3.9313e-05 - val_accuracy: 0.8384\n",
      "Epoch 169/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2966e-05 - accuracy: 0.8685 - val_loss: 3.9305e-05 - val_accuracy: 0.8384\n",
      "Epoch 170/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2957e-05 - accuracy: 0.8685 - val_loss: 3.9296e-05 - val_accuracy: 0.8384\n",
      "Epoch 171/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2947e-05 - accuracy: 0.8685 - val_loss: 3.9288e-05 - val_accuracy: 0.8384\n",
      "Epoch 172/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2938e-05 - accuracy: 0.8685 - val_loss: 3.9280e-05 - val_accuracy: 0.8384\n",
      "Epoch 173/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2929e-05 - accuracy: 0.8685 - val_loss: 3.9271e-05 - val_accuracy: 0.8384\n",
      "Epoch 174/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2920e-05 - accuracy: 0.8685 - val_loss: 3.9263e-05 - val_accuracy: 0.8384\n",
      "Epoch 175/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2911e-05 - accuracy: 0.8685 - val_loss: 3.9255e-05 - val_accuracy: 0.8384\n",
      "Epoch 176/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2903e-05 - accuracy: 0.8685 - val_loss: 3.9247e-05 - val_accuracy: 0.8384\n",
      "Epoch 177/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2894e-05 - accuracy: 0.8685 - val_loss: 3.9239e-05 - val_accuracy: 0.8384\n",
      "Epoch 178/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2885e-05 - accuracy: 0.8685 - val_loss: 3.9231e-05 - val_accuracy: 0.8384\n",
      "Epoch 179/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2877e-05 - accuracy: 0.8685 - val_loss: 3.9223e-05 - val_accuracy: 0.8384\n",
      "Epoch 180/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2868e-05 - accuracy: 0.8685 - val_loss: 3.9215e-05 - val_accuracy: 0.8384\n",
      "Epoch 181/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2859e-05 - accuracy: 0.8685 - val_loss: 3.9207e-05 - val_accuracy: 0.8384\n",
      "Epoch 182/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2851e-05 - accuracy: 0.8685 - val_loss: 3.9199e-05 - val_accuracy: 0.8384\n",
      "Epoch 183/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2843e-05 - accuracy: 0.8685 - val_loss: 3.9192e-05 - val_accuracy: 0.8384\n",
      "Epoch 184/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2834e-05 - accuracy: 0.8685 - val_loss: 3.9184e-05 - val_accuracy: 0.8384\n",
      "Epoch 185/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2826e-05 - accuracy: 0.8685 - val_loss: 3.9176e-05 - val_accuracy: 0.8384\n",
      "Epoch 186/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2818e-05 - accuracy: 0.8685 - val_loss: 3.9169e-05 - val_accuracy: 0.8384\n",
      "Epoch 187/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2809e-05 - accuracy: 0.8685 - val_loss: 3.9161e-05 - val_accuracy: 0.8384\n",
      "Epoch 188/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2801e-05 - accuracy: 0.8685 - val_loss: 3.9154e-05 - val_accuracy: 0.8384\n",
      "Epoch 189/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2793e-05 - accuracy: 0.8685 - val_loss: 3.9147e-05 - val_accuracy: 0.8384\n",
      "Epoch 190/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2785e-05 - accuracy: 0.8685 - val_loss: 3.9139e-05 - val_accuracy: 0.8384\n",
      "Epoch 191/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2777e-05 - accuracy: 0.8685 - val_loss: 3.9132e-05 - val_accuracy: 0.8384\n",
      "Epoch 192/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2769e-05 - accuracy: 0.8685 - val_loss: 3.9125e-05 - val_accuracy: 0.8384\n",
      "Epoch 193/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2762e-05 - accuracy: 0.8685 - val_loss: 3.9117e-05 - val_accuracy: 0.8384\n",
      "Epoch 194/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2754e-05 - accuracy: 0.8685 - val_loss: 3.9110e-05 - val_accuracy: 0.8384\n",
      "Epoch 195/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2746e-05 - accuracy: 0.8685 - val_loss: 3.9103e-05 - val_accuracy: 0.8384\n",
      "Epoch 196/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2738e-05 - accuracy: 0.8685 - val_loss: 3.9096e-05 - val_accuracy: 0.8384\n",
      "Epoch 197/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2730e-05 - accuracy: 0.8685 - val_loss: 3.9089e-05 - val_accuracy: 0.8384\n",
      "Epoch 198/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2723e-05 - accuracy: 0.8685 - val_loss: 3.9082e-05 - val_accuracy: 0.8384\n",
      "Epoch 199/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2715e-05 - accuracy: 0.8685 - val_loss: 3.9075e-05 - val_accuracy: 0.8384\n",
      "Epoch 200/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2708e-05 - accuracy: 0.8685 - val_loss: 3.9069e-05 - val_accuracy: 0.8384\n",
      "Epoch 201/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2700e-05 - accuracy: 0.8685 - val_loss: 3.9062e-05 - val_accuracy: 0.8384\n",
      "Epoch 202/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2693e-05 - accuracy: 0.8685 - val_loss: 3.9055e-05 - val_accuracy: 0.8384\n",
      "Epoch 203/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2685e-05 - accuracy: 0.8685 - val_loss: 3.9048e-05 - val_accuracy: 0.8384\n",
      "Epoch 204/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2678e-05 - accuracy: 0.8685 - val_loss: 3.9042e-05 - val_accuracy: 0.8384\n",
      "Epoch 205/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2671e-05 - accuracy: 0.8685 - val_loss: 3.9035e-05 - val_accuracy: 0.8384\n",
      "Epoch 206/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2664e-05 - accuracy: 0.8685 - val_loss: 3.9028e-05 - val_accuracy: 0.8384\n",
      "Epoch 207/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2656e-05 - accuracy: 0.8685 - val_loss: 3.9022e-05 - val_accuracy: 0.8384\n",
      "Epoch 208/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2649e-05 - accuracy: 0.8685 - val_loss: 3.9015e-05 - val_accuracy: 0.8384\n",
      "Epoch 209/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2642e-05 - accuracy: 0.8685 - val_loss: 3.9009e-05 - val_accuracy: 0.8384\n",
      "Epoch 210/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2635e-05 - accuracy: 0.8685 - val_loss: 3.9002e-05 - val_accuracy: 0.8384\n",
      "Epoch 211/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2628e-05 - accuracy: 0.8685 - val_loss: 3.8996e-05 - val_accuracy: 0.8384\n",
      "Epoch 212/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2621e-05 - accuracy: 0.8685 - val_loss: 3.8989e-05 - val_accuracy: 0.8384\n",
      "Epoch 213/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2614e-05 - accuracy: 0.8685 - val_loss: 3.8983e-05 - val_accuracy: 0.8384\n",
      "Epoch 214/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2607e-05 - accuracy: 0.8685 - val_loss: 3.8977e-05 - val_accuracy: 0.8384\n",
      "Epoch 215/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2600e-05 - accuracy: 0.8685 - val_loss: 3.8971e-05 - val_accuracy: 0.8384\n",
      "Epoch 216/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2593e-05 - accuracy: 0.8685 - val_loss: 3.8964e-05 - val_accuracy: 0.8384\n",
      "Epoch 217/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2587e-05 - accuracy: 0.8685 - val_loss: 3.8958e-05 - val_accuracy: 0.8384\n",
      "Epoch 218/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2580e-05 - accuracy: 0.8685 - val_loss: 3.8952e-05 - val_accuracy: 0.8384\n",
      "Epoch 219/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2573e-05 - accuracy: 0.8685 - val_loss: 3.8946e-05 - val_accuracy: 0.8384\n",
      "Epoch 220/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2567e-05 - accuracy: 0.8685 - val_loss: 3.8940e-05 - val_accuracy: 0.8384\n",
      "Epoch 221/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2560e-05 - accuracy: 0.8685 - val_loss: 3.8934e-05 - val_accuracy: 0.8384\n",
      "Epoch 222/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2553e-05 - accuracy: 0.8685 - val_loss: 3.8928e-05 - val_accuracy: 0.8384\n",
      "Epoch 223/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2547e-05 - accuracy: 0.8685 - val_loss: 3.8922e-05 - val_accuracy: 0.8384\n",
      "Epoch 224/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2540e-05 - accuracy: 0.8685 - val_loss: 3.8916e-05 - val_accuracy: 0.8384\n",
      "Epoch 225/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2534e-05 - accuracy: 0.8685 - val_loss: 3.8910e-05 - val_accuracy: 0.8384\n",
      "Epoch 226/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2527e-05 - accuracy: 0.8685 - val_loss: 3.8905e-05 - val_accuracy: 0.8384\n",
      "Epoch 227/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2521e-05 - accuracy: 0.8685 - val_loss: 3.8899e-05 - val_accuracy: 0.8384\n",
      "Epoch 228/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2515e-05 - accuracy: 0.8685 - val_loss: 3.8893e-05 - val_accuracy: 0.8384\n",
      "Epoch 229/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2508e-05 - accuracy: 0.8685 - val_loss: 3.8887e-05 - val_accuracy: 0.8384\n",
      "Epoch 230/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2502e-05 - accuracy: 0.8685 - val_loss: 3.8882e-05 - val_accuracy: 0.8384\n",
      "Epoch 231/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2496e-05 - accuracy: 0.8685 - val_loss: 3.8876e-05 - val_accuracy: 0.8384\n",
      "Epoch 232/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2490e-05 - accuracy: 0.8685 - val_loss: 3.8870e-05 - val_accuracy: 0.8384\n",
      "Epoch 233/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2483e-05 - accuracy: 0.8685 - val_loss: 3.8865e-05 - val_accuracy: 0.8384\n",
      "Epoch 234/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2477e-05 - accuracy: 0.8685 - val_loss: 3.8859e-05 - val_accuracy: 0.8384\n",
      "Epoch 235/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2471e-05 - accuracy: 0.8685 - val_loss: 3.8854e-05 - val_accuracy: 0.8384\n",
      "Epoch 236/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2465e-05 - accuracy: 0.8685 - val_loss: 3.8849e-05 - val_accuracy: 0.8384\n",
      "Epoch 237/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2459e-05 - accuracy: 0.8685 - val_loss: 3.8843e-05 - val_accuracy: 0.8384\n",
      "Epoch 238/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2453e-05 - accuracy: 0.8685 - val_loss: 3.8838e-05 - val_accuracy: 0.8384\n",
      "Epoch 239/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2447e-05 - accuracy: 0.8685 - val_loss: 3.8832e-05 - val_accuracy: 0.8384\n",
      "Epoch 240/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2441e-05 - accuracy: 0.8685 - val_loss: 3.8827e-05 - val_accuracy: 0.8384\n",
      "Epoch 241/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2435e-05 - accuracy: 0.8685 - val_loss: 3.8822e-05 - val_accuracy: 0.8384\n",
      "Epoch 242/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2429e-05 - accuracy: 0.8685 - val_loss: 3.8817e-05 - val_accuracy: 0.8384\n",
      "Epoch 243/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2424e-05 - accuracy: 0.8685 - val_loss: 3.8811e-05 - val_accuracy: 0.8384\n",
      "Epoch 244/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2418e-05 - accuracy: 0.8685 - val_loss: 3.8806e-05 - val_accuracy: 0.8384\n",
      "Epoch 245/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2412e-05 - accuracy: 0.8685 - val_loss: 3.8801e-05 - val_accuracy: 0.8384\n",
      "Epoch 246/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2406e-05 - accuracy: 0.8685 - val_loss: 3.8796e-05 - val_accuracy: 0.8384\n",
      "Epoch 247/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2401e-05 - accuracy: 0.8685 - val_loss: 3.8791e-05 - val_accuracy: 0.8384\n",
      "Epoch 248/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2395e-05 - accuracy: 0.8685 - val_loss: 3.8785e-05 - val_accuracy: 0.8384\n",
      "Epoch 249/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2389e-05 - accuracy: 0.8685 - val_loss: 3.8780e-05 - val_accuracy: 0.8384\n",
      "Epoch 250/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2384e-05 - accuracy: 0.8685 - val_loss: 3.8775e-05 - val_accuracy: 0.8384\n",
      "Epoch 251/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2378e-05 - accuracy: 0.8685 - val_loss: 3.8770e-05 - val_accuracy: 0.8384\n",
      "Epoch 252/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2373e-05 - accuracy: 0.8685 - val_loss: 3.8765e-05 - val_accuracy: 0.8384\n",
      "Epoch 253/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2367e-05 - accuracy: 0.8685 - val_loss: 3.8760e-05 - val_accuracy: 0.8384\n",
      "Epoch 254/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2362e-05 - accuracy: 0.8685 - val_loss: 3.8755e-05 - val_accuracy: 0.8384\n",
      "Epoch 255/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2356e-05 - accuracy: 0.8685 - val_loss: 3.8750e-05 - val_accuracy: 0.8384\n",
      "Epoch 256/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2351e-05 - accuracy: 0.8685 - val_loss: 3.8745e-05 - val_accuracy: 0.8384\n",
      "Epoch 257/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2345e-05 - accuracy: 0.8685 - val_loss: 3.8740e-05 - val_accuracy: 0.8384\n",
      "Epoch 258/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2340e-05 - accuracy: 0.8685 - val_loss: 3.8735e-05 - val_accuracy: 0.8384\n",
      "Epoch 259/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2334e-05 - accuracy: 0.8685 - val_loss: 3.8731e-05 - val_accuracy: 0.8384\n",
      "Epoch 260/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2329e-05 - accuracy: 0.8685 - val_loss: 3.8726e-05 - val_accuracy: 0.8384\n",
      "Epoch 261/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2324e-05 - accuracy: 0.8685 - val_loss: 3.8721e-05 - val_accuracy: 0.8384\n",
      "Epoch 262/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2319e-05 - accuracy: 0.8685 - val_loss: 3.8716e-05 - val_accuracy: 0.8384\n",
      "Epoch 263/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2313e-05 - accuracy: 0.8685 - val_loss: 3.8712e-05 - val_accuracy: 0.8384\n",
      "Epoch 264/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2308e-05 - accuracy: 0.8685 - val_loss: 3.8707e-05 - val_accuracy: 0.8384\n",
      "Epoch 265/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2303e-05 - accuracy: 0.8685 - val_loss: 3.8703e-05 - val_accuracy: 0.8384\n",
      "Epoch 266/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2298e-05 - accuracy: 0.8685 - val_loss: 3.8698e-05 - val_accuracy: 0.8384\n",
      "Epoch 267/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2293e-05 - accuracy: 0.8685 - val_loss: 3.8693e-05 - val_accuracy: 0.8384\n",
      "Epoch 268/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2288e-05 - accuracy: 0.8685 - val_loss: 3.8689e-05 - val_accuracy: 0.8384\n",
      "Epoch 269/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2283e-05 - accuracy: 0.8685 - val_loss: 3.8684e-05 - val_accuracy: 0.8384\n",
      "Epoch 270/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2277e-05 - accuracy: 0.8685 - val_loss: 3.8680e-05 - val_accuracy: 0.8384\n",
      "Epoch 271/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2272e-05 - accuracy: 0.8685 - val_loss: 3.8675e-05 - val_accuracy: 0.8384\n",
      "Epoch 272/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2267e-05 - accuracy: 0.8685 - val_loss: 3.8671e-05 - val_accuracy: 0.8384\n",
      "Epoch 273/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2262e-05 - accuracy: 0.8685 - val_loss: 3.8666e-05 - val_accuracy: 0.8384\n",
      "Epoch 274/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2258e-05 - accuracy: 0.8685 - val_loss: 3.8662e-05 - val_accuracy: 0.8384\n",
      "Epoch 275/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2253e-05 - accuracy: 0.8685 - val_loss: 3.8658e-05 - val_accuracy: 0.8384\n",
      "Epoch 276/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2248e-05 - accuracy: 0.8685 - val_loss: 3.8653e-05 - val_accuracy: 0.8384\n",
      "Epoch 277/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2243e-05 - accuracy: 0.8685 - val_loss: 3.8649e-05 - val_accuracy: 0.8384\n",
      "Epoch 278/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2238e-05 - accuracy: 0.8685 - val_loss: 3.8644e-05 - val_accuracy: 0.8384\n",
      "Epoch 279/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2233e-05 - accuracy: 0.8685 - val_loss: 3.8640e-05 - val_accuracy: 0.8384\n",
      "Epoch 280/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2228e-05 - accuracy: 0.8685 - val_loss: 3.8636e-05 - val_accuracy: 0.8384\n",
      "Epoch 281/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2224e-05 - accuracy: 0.8685 - val_loss: 3.8631e-05 - val_accuracy: 0.8384\n",
      "Epoch 282/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2219e-05 - accuracy: 0.8685 - val_loss: 3.8627e-05 - val_accuracy: 0.8384\n",
      "Epoch 283/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2214e-05 - accuracy: 0.8685 - val_loss: 3.8623e-05 - val_accuracy: 0.8384\n",
      "Epoch 284/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2209e-05 - accuracy: 0.8685 - val_loss: 3.8619e-05 - val_accuracy: 0.8384\n",
      "Epoch 285/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2205e-05 - accuracy: 0.8685 - val_loss: 3.8615e-05 - val_accuracy: 0.8384\n",
      "Epoch 286/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2200e-05 - accuracy: 0.8685 - val_loss: 3.8611e-05 - val_accuracy: 0.8384\n",
      "Epoch 287/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2196e-05 - accuracy: 0.8685 - val_loss: 3.8606e-05 - val_accuracy: 0.8384\n",
      "Epoch 288/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2191e-05 - accuracy: 0.8685 - val_loss: 3.8602e-05 - val_accuracy: 0.8384\n",
      "Epoch 289/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2186e-05 - accuracy: 0.8685 - val_loss: 3.8598e-05 - val_accuracy: 0.8384\n",
      "Epoch 290/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2182e-05 - accuracy: 0.8685 - val_loss: 3.8594e-05 - val_accuracy: 0.8384\n",
      "Epoch 291/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2177e-05 - accuracy: 0.8685 - val_loss: 3.8590e-05 - val_accuracy: 0.8384\n",
      "Epoch 292/300\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2173e-05 - accuracy: 0.8685 - val_loss: 3.8586e-05 - val_accuracy: 0.8384\n",
      "Epoch 293/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2168e-05 - accuracy: 0.8685 - val_loss: 3.8582e-05 - val_accuracy: 0.8384\n",
      "Epoch 294/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2164e-05 - accuracy: 0.8685 - val_loss: 3.8578e-05 - val_accuracy: 0.8384\n",
      "Epoch 295/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2159e-05 - accuracy: 0.8685 - val_loss: 3.8574e-05 - val_accuracy: 0.8384\n",
      "Epoch 296/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2155e-05 - accuracy: 0.8685 - val_loss: 3.8570e-05 - val_accuracy: 0.8384\n",
      "Epoch 297/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2151e-05 - accuracy: 0.8685 - val_loss: 3.8566e-05 - val_accuracy: 0.8384\n",
      "Epoch 298/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2146e-05 - accuracy: 0.8685 - val_loss: 3.8563e-05 - val_accuracy: 0.8384\n",
      "Epoch 299/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2142e-05 - accuracy: 0.8685 - val_loss: 3.8559e-05 - val_accuracy: 0.8384\n",
      "Epoch 300/300\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2137e-05 - accuracy: 0.8685 - val_loss: 3.8555e-05 - val_accuracy: 0.8384\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181b21fa3d0>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=60,\n",
    "    epochs=300,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "source": [
    "### Извлечение весов"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[-0.40879568,  0.43820944, -0.5155866 , -0.23618193, -0.38700268],\n",
       "        [ 0.5629005 ,  0.3966952 ,  0.29153004,  0.02181255,  0.20639306],\n",
       "        [-0.5459437 ,  0.14200647, -0.41047236, -0.06354537, -0.21435219],\n",
       "        [ 0.21074991,  0.42638266, -0.44166276,  0.38482136, -0.27756816],\n",
       "        [-0.37357906, -0.21806642,  0.06805609,  0.62163293, -0.54357594],\n",
       "        [-0.5582701 , -0.49424145,  0.1618319 , -0.41267198, -0.19749175],\n",
       "        [-0.35455048, -0.45996833, -0.17314659,  0.16245966,  0.2349942 ],\n",
       "        [-0.15985003,  0.09018525, -0.42140886, -0.04584203,  0.25662354],\n",
       "        [-0.58278877,  0.36669543, -0.03091229, -0.45878106,  0.65625995],\n",
       "        [-0.18475012,  0.04909425,  0.24040343,  0.6145781 , -0.19709116]],\n",
       "       dtype=float32),\n",
       " array([1.017216 , 1.536221 , 1.5503241, 1.2648007, 1.330532 ],\n",
       "       dtype=float32),\n",
       " array([[-0.22051446, -0.8384615 , -0.5561618 , -0.7544058 , -0.51145035,\n",
       "         -0.6948674 , -1.2957828 , -0.8218235 , -1.1272982 , -0.9140862 ],\n",
       "        [-1.0484376 , -0.3801621 , -1.5131838 , -0.8338207 , -1.0811476 ,\n",
       "         -0.87702787, -1.391079  , -0.89805233, -0.54952085, -1.5116991 ],\n",
       "        [-0.82506734, -1.1603286 , -1.2987055 , -1.1765703 , -1.6597078 ,\n",
       "         -1.1254193 , -0.91885823, -0.7969371 , -0.9420119 , -0.52931356],\n",
       "        [-1.2069241 , -0.28672096, -0.8494858 , -0.8968018 , -1.1850921 ,\n",
       "         -0.9977652 , -0.7912544 , -0.9096968 , -0.41672882, -0.9876639 ],\n",
       "        [-0.46144938, -0.7657799 , -0.94975436, -0.9416727 , -1.5008677 ,\n",
       "         -0.49244067, -1.1985997 , -1.0261676 , -0.939591  , -0.8228172 ]],\n",
       "       dtype=float32),\n",
       " array([-0.9237175 , -0.41249695, -1.6396667 , -1.7287335 , -1.8818867 ,\n",
       "        -1.3375382 , -1.9721929 , -0.7630171 , -0.63287115, -1.4743652 ],\n",
       "       dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}